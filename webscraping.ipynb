{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Digital Futures](https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/datascience-notebook-header.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project Environment\n",
    "\n",
    "Ultimately, the Python code written here will be extracted to scripts for execution in an automated pipeline.  To facilitate this, there is a need to set up a project environment that will allow for the execution of the code in a controlled and reproducible environment.\n",
    "\n",
    "In the initial stages of the activities, the packages needed are `requests` and `pytest`.  The `requests` package is used to make HTTP requests to the API, while `pytest` is used for testing the code we also need *BeautifulSoup* (package name `beautifulsoup4`.  In later activities, you may need to install additional packages.  To do this, add the packages to the `pip install` command below and re-run the cell.\n",
    "\n",
    "> **Remember:** The goal is to create a set of code cells that can be extracted to separate scripts for execution in an automated pipeline.  Therefore, the code should be kept in 3 distinct cells:\n",
    "> \n",
    "> - **Shell Commands**:  Used to set up the project environment\n",
    "> \n",
    "> - **Python Tests**: Used to test the Python production scripts both now and as part of the automated pipeline\n",
    "> \n",
    "> - **Python Production Code**: The Python code that will be extracted to a script to execute during the pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup Scripts\n",
    "\n",
    "If you are running this notebook after cloning and have not set up your environment to run shell commands, you will need to run the following commands in your terminal to set up the environment.\n",
    "\n",
    "> **NOTE:**  These commands need to be executed in the terminal.  \n",
    ">\n",
    "> Open a terminal at the root of your project before executing these commands\n",
    "> \n",
    "> Until your environment is set up, Jupyter Notebooks will not be able to run **shell** scripts.\n",
    "\n",
    "```sh\n",
    "# Create a virtual environment (add the command below)\n",
    "python3 -m venv .venv # Note: This command could also be python -m venv .venv # python3 and python are a symlink to the python version installed on your system\n",
    "\n",
    "# Activate the virtual environment \n",
    "source .venv/bin/activate\n",
    "\n",
    "# Install required package to execute shell commands from Jupyter Notebook\n",
    "pip install ipykernel               ## OR \n",
    "pip install -r requirements.txt     ## IF there is already a requirements.txt file CONTAINING ipykenrnel in the project\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the necessary packages\n",
    "!pip install requests pytest beautifulsoup4\n",
    "\n",
    "# Create a requirements.txt file\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    "> The `!` at the beginning of the lines is a special character in Jupyter Notebooks that allows you to run shell commands from the notebook.  \n",
    "> These will need to be removed from any commands that are to be exported to a `.sh` shell script file for the pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tests\n",
    "\n",
    "Develop any tests for functions in separate cells below.  The first has been provided for you as an example, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_URL = 'https://www.testsite.com'\n",
    "TEST_HTML = '<html><body><h1>Hello, World!</h1></body></html>'\n",
    "SUCCESS_STATUS = \"success\"\n",
    "ERROR_STATUS = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "NAV_HTML_WITH_CLASS = '<ul class=\"nav nav-list\"><li>Item</li></ul>'\n",
    "NAV_HTML_WITHOUT_CLASS = '<ul><li>Item</li></ul>'\n",
    "NAV_HTML_WITHOUT_UL_TAG = '<div class=\"content\"><p>No ul here</p></div>'\n",
    "NAV_HTML_WITH_DIFFERENT_CLASS = '''\n",
    "<ul class=\"different-class\"><li>Item</li></ul>\n",
    "'''\n",
    "NAV_HTML_INVALID = '<ul class=\"nav nav-list\"><li>Item'\n",
    "HTML_PARSER = 'html.parser'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `request_to_scrape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test request_to_scrape\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "\n",
    "def test_request_to_scrape_makes_correct_request():\n",
    "    \"\"\"\n",
    "    Test that the function makes a request to the correct URL.\n",
    "    \"\"\"\n",
    "    TEST_URL = 'https://www.testsite.com'\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        request_to_scrape(TEST_URL)\n",
    "        mock_get.assert_called_once_with(TEST_URL, timeout=10)\n",
    "\n",
    "test_request_to_scrape_makes_correct_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_request_to_scrape_returns_html_for_200():\n",
    "    \"\"\"\n",
    "    Test that the function returns the HTML content\n",
    "    when the request is successful (status code 200).\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        mock_get.return_value.headers = {'Content-Type': 'text/html'}\n",
    "        mock_get.return_value.text = TEST_HTML\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": SUCCESS_STATUS,\n",
    "            \"data\": TEST_HTML\n",
    "        }\n",
    "        \n",
    "test_request_to_scrape_returns_html_for_200()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_request_to_scrape_handles_non_200():\n",
    "    \"\"\"\n",
    "    Test that the function returns an error message\n",
    "    when the response status code is not 200.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 404\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": ERROR_NOT_HTML\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"exception, error_message\", [\n",
    "    (\n",
    "        Exception(\"An error occurred\"),\n",
    "        \"An error occurred - Unexpected error for URL\"\n",
    "    ),\n",
    "    (\n",
    "        Timeout(\"The request timed out\"),\n",
    "        \"The request timed out - Request failed for URL\"\n",
    "    ),\n",
    "    (\n",
    "        RequestException(\"Invalid URL\"),\n",
    "        \"Invalid URL - Request failed for URL\"\n",
    "    )\n",
    "])\n",
    "def test_request_to_scrape_handles_exceptions(exception, error_message):\n",
    "    \"\"\"\n",
    "    Test that the function returns an error message \n",
    "    when an exception occurs during the request.\n",
    "    \"\"\"\n",
    "    with patch('requests.get') as mock_get:\n",
    "        mock_get.side_effect = exception\n",
    "        result = request_to_scrape(TEST_URL)\n",
    "        assert result == {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": error_message\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `extract_element`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extract_element\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_with_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITH_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_without_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITHOUT_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_without_tag():\n",
    "    return BeautifulSoup(NAV_HTML_WITHOUT_UL_TAG, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def soup_with_different_class():\n",
    "    return BeautifulSoup(NAV_HTML_WITH_DIFFERENT_CLASS, HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def empty_soup():\n",
    "    return BeautifulSoup('', HTML_PARSER)\n",
    "\n",
    "@pytest.fixture\n",
    "def invalid_soup():\n",
    "    return BeautifulSoup(NAV_HTML_INVALID, HTML_PARSER)\n",
    "\n",
    "def test_extract_element_with_valid_html_with_class(\n",
    "    soup_with_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` correctly extracts an element with a specific class.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_with_class, 'ul', 'nav nav-list')\n",
    "    assert element is not None\n",
    "    assert element['class'] == ['nav', 'nav-list']\n",
    "\n",
    "def test_extract_element_with_valid_html_without_class(\n",
    "    soup_without_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` correctly extracts an element without a class.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_without_class, 'ul')\n",
    "    assert element is not None\n",
    "    assert element.name == 'ul'\n",
    "\n",
    "def test_extract_element_with_html_without_tag(\n",
    "    soup_without_tag\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when the specified tag is not present.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_without_tag, 'ul')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_html_with_different_class(\n",
    "    soup_with_different_class\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when the class does not match.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(soup_with_different_class, 'ul', 'nav nav-list')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_empty_html(\n",
    "    empty_soup\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` returns None when provided with empty HTML content.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(empty_soup, 'ul')\n",
    "    assert element is None\n",
    "\n",
    "def test_extract_element_with_invalid_html(\n",
    "    invalid_soup\n",
    "):\n",
    "    \"\"\"\n",
    "    Test that `extract_element` can handle and correctly parse invalid HTML input.\n",
    "    \"\"\"  # noqa E501\n",
    "    element = extract_element(invalid_soup, 'ul', 'nav nav-list')\n",
    "    assert element is not None\n",
    "    assert element['class'] == ['nav', 'nav-list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tests\n",
    "\n",
    "Run the cell containing the `ipytest.run()` command to execute the tests.  The tests should all fail until you have written the production code.\n",
    "\n",
    "Don't forget to run the installation and initialisation cell too on the first time you run the tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Python Production Code\n",
    "\n",
    "\n",
    "Develop any functions for use as production code in separate cells below. The first has been provided as an example under the Production Constants, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCTION CONSTANTS\n",
    "\n",
    "# Constants for status messages\n",
    "STATUS_SUCCESS = \"success\"\n",
    "ERROR_STATUS = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "ERROR_REQUEST_FAILED = \"Request failed for URL\"\n",
    "ERROR_UNEXPECTED = \"Unexpected error for URL\"\n",
    "\n",
    "# HTML Parser\n",
    "HTML_PARSER = \"html.parser\"\n",
    "\n",
    "URL = \"https://books.toscrape.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `request_to_scrape` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request_to_scrape Production Code\n",
    "import requests\n",
    "from requests.exceptions import RequestException, Timeout\n",
    "\n",
    "def request_to_scrape(url: str, timeout: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an HTTP GET request to the specified URL and returns the response content.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to which the GET request is sent.\n",
    "        timeout (int, optional): The timeout for the request in seconds. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the status, data, and any error messages.\n",
    "                        - If the request is successful and returns HTML, 'status' is 'success' and 'data' contains the response text.\n",
    "                        - If the request fails or does not return HTML, 'status' is 'error' and 'error' contains the error message.\n",
    "    \"\"\"  # noqa: E501\n",
    "    try:\n",
    "        response = requests.get(url, timeout=timeout)\n",
    "        # Raise an HTTPError for bad responses\n",
    "        response.raise_for_status()\n",
    "        # Check if the response contains HTML\n",
    "        if 'text/html' in response.headers.get('Content-Type', ''):\n",
    "            return {\n",
    "                \"status\": STATUS_SUCCESS,\n",
    "                \"data\": response.text\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"status\": ERROR_STATUS,\n",
    "                \"error\": ERROR_NOT_HTML\n",
    "            }\n",
    "    except (Timeout, RequestException) as e:\n",
    "        return {\n",
    "            \"status\": ERROR_STATUS,\n",
    "            \"error\": f\"{str(e)} - {ERROR_REQUEST_FAILED}\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"error\": f\"{str(e)} - {ERROR_UNEXPECTED}\"\n",
    "        }\n",
    "\n",
    "#request_to_scrape(URL)\n",
    "#test_request_to_scrape_handles_exceptions(Exception(\"An error occurred\"),\"An error occurred - Unexpected error for URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_book_categories` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Travel': {'link': 'https://books.toscrape.com//catalogue/category/books/travel_2/index.html'},\n",
       " 'Mystery': {'link': 'https://books.toscrape.com//catalogue/category/books/mystery_3/index.html'},\n",
       " 'Historical Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/historical-fiction_4/index.html'},\n",
       " 'Sequential Art': {'link': 'https://books.toscrape.com//catalogue/category/books/sequential-art_5/index.html'},\n",
       " 'Classics': {'link': 'https://books.toscrape.com//catalogue/category/books/classics_6/index.html'},\n",
       " 'Philosophy': {'link': 'https://books.toscrape.com//catalogue/category/books/philosophy_7/index.html'},\n",
       " 'Romance': {'link': 'https://books.toscrape.com//catalogue/category/books/romance_8/index.html'},\n",
       " 'Womens Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/womens-fiction_9/index.html'},\n",
       " 'Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/fiction_10/index.html'},\n",
       " 'Childrens': {'link': 'https://books.toscrape.com//catalogue/category/books/childrens_11/index.html'},\n",
       " 'Religion': {'link': 'https://books.toscrape.com//catalogue/category/books/religion_12/index.html'},\n",
       " 'Nonfiction': {'link': 'https://books.toscrape.com//catalogue/category/books/nonfiction_13/index.html'},\n",
       " 'Music': {'link': 'https://books.toscrape.com//catalogue/category/books/music_14/index.html'},\n",
       " 'Default': {'link': 'https://books.toscrape.com//catalogue/category/books/default_15/index.html'},\n",
       " 'Science Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/science-fiction_16/index.html'},\n",
       " 'Sports and Games': {'link': 'https://books.toscrape.com//catalogue/category/books/sports-and-games_17/index.html'},\n",
       " 'Add a comment': {'link': 'https://books.toscrape.com//catalogue/category/books/add-a-comment_18/index.html'},\n",
       " 'Fantasy': {'link': 'https://books.toscrape.com//catalogue/category/books/fantasy_19/index.html'},\n",
       " 'New Adult': {'link': 'https://books.toscrape.com//catalogue/category/books/new-adult_20/index.html'},\n",
       " 'Young Adult': {'link': 'https://books.toscrape.com//catalogue/category/books/young-adult_21/index.html'},\n",
       " 'Science': {'link': 'https://books.toscrape.com//catalogue/category/books/science_22/index.html'},\n",
       " 'Poetry': {'link': 'https://books.toscrape.com//catalogue/category/books/poetry_23/index.html'},\n",
       " 'Paranormal': {'link': 'https://books.toscrape.com//catalogue/category/books/paranormal_24/index.html'},\n",
       " 'Art': {'link': 'https://books.toscrape.com//catalogue/category/books/art_25/index.html'},\n",
       " 'Psychology': {'link': 'https://books.toscrape.com//catalogue/category/books/psychology_26/index.html'},\n",
       " 'Autobiography': {'link': 'https://books.toscrape.com//catalogue/category/books/autobiography_27/index.html'},\n",
       " 'Parenting': {'link': 'https://books.toscrape.com//catalogue/category/books/parenting_28/index.html'},\n",
       " 'Adult Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/adult-fiction_29/index.html'},\n",
       " 'Humor': {'link': 'https://books.toscrape.com//catalogue/category/books/humor_30/index.html'},\n",
       " 'Horror': {'link': 'https://books.toscrape.com//catalogue/category/books/horror_31/index.html'},\n",
       " 'History': {'link': 'https://books.toscrape.com//catalogue/category/books/history_32/index.html'},\n",
       " 'Food and Drink': {'link': 'https://books.toscrape.com//catalogue/category/books/food-and-drink_33/index.html'},\n",
       " 'Christian Fiction': {'link': 'https://books.toscrape.com//catalogue/category/books/christian-fiction_34/index.html'},\n",
       " 'Business': {'link': 'https://books.toscrape.com//catalogue/category/books/business_35/index.html'},\n",
       " 'Biography': {'link': 'https://books.toscrape.com//catalogue/category/books/biography_36/index.html'},\n",
       " 'Thriller': {'link': 'https://books.toscrape.com//catalogue/category/books/thriller_37/index.html'},\n",
       " 'Contemporary': {'link': 'https://books.toscrape.com//catalogue/category/books/contemporary_38/index.html'},\n",
       " 'Spirituality': {'link': 'https://books.toscrape.com//catalogue/category/books/spirituality_39/index.html'},\n",
       " 'Academic': {'link': 'https://books.toscrape.com//catalogue/category/books/academic_40/index.html'},\n",
       " 'Self Help': {'link': 'https://books.toscrape.com//catalogue/category/books/self-help_41/index.html'},\n",
       " 'Historical': {'link': 'https://books.toscrape.com//catalogue/category/books/historical_42/index.html'},\n",
       " 'Christian': {'link': 'https://books.toscrape.com//catalogue/category/books/christian_43/index.html'},\n",
       " 'Suspense': {'link': 'https://books.toscrape.com//catalogue/category/books/suspense_44/index.html'},\n",
       " 'Short Stories': {'link': 'https://books.toscrape.com//catalogue/category/books/short-stories_45/index.html'},\n",
       " 'Novels': {'link': 'https://books.toscrape.com//catalogue/category/books/novels_46/index.html'},\n",
       " 'Health': {'link': 'https://books.toscrape.com//catalogue/category/books/health_47/index.html'},\n",
       " 'Politics': {'link': 'https://books.toscrape.com//catalogue/category/books/politics_48/index.html'},\n",
       " 'Cultural': {'link': 'https://books.toscrape.com//catalogue/category/books/cultural_49/index.html'},\n",
       " 'Erotica': {'link': 'https://books.toscrape.com//catalogue/category/books/erotica_50/index.html'},\n",
       " 'Crime': {'link': 'https://books.toscrape.com//catalogue/category/books/crime_51/index.html'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `extract_book_categories` Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HTML = request_to_scrape(URL)['data']\n",
    "def extract_book_categories(html: str, site: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts book categories and their corresponding links from the provided HTML content.\n",
    "    Args:\n",
    "    \n",
    "        html (str): The HTML content of the webpage to parse.\n",
    "        site (str): The URL of the site from which the HTML content was retrieved.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are category names and the values dictionaries containing the corresponding links.\n",
    "    \"\"\"  # noqa: E501\n",
    "    soup = BeautifulSoup(html, HTML_PARSER)\n",
    "    nav_list = extract_element(soup, 'ul', 'nav nav-list')\n",
    "    if nav_list is None:\n",
    "        return {}\n",
    "    category_list = extract_element(nav_list, 'ul')\n",
    "    categories = extract_categories_and_links(category_list, site)\n",
    "    return categories\n",
    "\n",
    "extract_book_categories(HTML, URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_element` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_element Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_element(\n",
    "    soup: BeautifulSoup, tag: str, class_name: str = None\n",
    ") -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Extracts an HTML element from a BeautifulSoup object based on the specified tag and optional class name.\n",
    "    Args:\n",
    "        soup (BeautifulSoup): The BeautifulSoup object to search within.\n",
    "        tag (str): The HTML tag to search for.\n",
    "        class_name (str, optional): The class name to filter the search. Defaults to None.\n",
    "    Returns:\n",
    "        Tag or None: The first matching Tag object if found, otherwise None.\n",
    "    \"\"\"  # noqa: E501\n",
    "    if soup is None:\n",
    "        return None\n",
    "    return soup.find(tag, class_=class_name) if class_name else soup.find(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `extract_categories_and_links` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `extract_categories_and_links` Production Code\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_categories_and_links(\n",
    "    category_list: BeautifulSoup, site: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Extracts categories and their corresponding links from a given list of HTML anchor elements.\n",
    "    Args:\n",
    "        category_list (BeautifulSoup object): A BeautifulSoup object containing a list of HTML anchor elements.\n",
    "        site (str): The site URL to append to relative links.\n",
    "    Returns:\n",
    "        dictionary: A dictionary of dictionaries where the keys are category names (str) and the values are the corresponding href links (str) in a dictionary.\n",
    "        e.g.\n",
    "        {\n",
    "            'Category 1': {'link': 'https://www.example.com/category1.html'},\n",
    "            'Category 2': {'link': 'https://www.example.com/category2.html'}\n",
    "        }\n",
    "    \"\"\"  # noqa: E501\n",
    "    if not category_list:\n",
    "        return {}\n",
    "\n",
    "    categories = {}\n",
    "    for link in category_list.find_all('a'):\n",
    "        category_name = link.get_text(strip=True)\n",
    "        category_href = link.get('href')\n",
    "        categories[category_name] = {\n",
    "            'link': f\"{site}/{category_href}\" if category_href else None\n",
    "        }\n",
    "\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Python Execution Code\n",
    "\n",
    "Develop any code to call the developed functions below.  Add additional cells so you don't need to re-run all of the code when you develop further scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Test and Linting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `pytest` scripts in a Jupyter Notebook cell, we need to install the `ipytest` package.  This package is NOT required for a pipeline and therefore it can be removed from the `requirements.txt` file before adding the production code to the pipeline.\n",
    "\n",
    "To run linting, we need to install 2 packages `nbqa` and `flake8`.  We will make sure that `flake8` is included in the `requirements.txt` file when constructing the pipeline so that we can lint as part of the pipeline tests.\n",
    "\n",
    "Run the following cell to install the `ipytest`, `nbqa` and `flake8` packages and a coverage package to help determine if all of your production code is executed during the tests!\n",
    "\n",
    "This cell only needs to be run once (or after restarting the notebook kernel) to set up the environment for testing and linting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the `ipytest`, `nbqa` and `flake8` packages\n",
    "!pip install ipytest nbqa flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `ipytest` to execute `pytest` scripts in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ipytest for Jupyter Notebook\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig(rewrite_asserts=True, magics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a *config* file for `flake8`\n",
    "\n",
    "Run this script to create a file in your project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a config file and ignore some flake8 rules\n",
    "!echo \"[flake8]\" > .flake8\n",
    "!echo \"ignore = E402, W291, F811\" >> .flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the tests and linting in the Jupyter Notebook\n",
    "\n",
    "Run the following cell ***EVERY TIME*** you want to run the tests and linting that you have written in the *Python Tests* cell above.\n",
    "\n",
    ">**Note:**\n",
    ">\n",
    "> This entire section does not need to be part of any pipeline scripts.  \n",
    "> It is only required for the Jupyter Notebook environment during development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "ipytest.run(\"-vv\", \"-ss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the linter\n",
    "\n",
    "Run this script each time you want to lint your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Run the linter\n",
    "!nbqa flake8 --show-source --format=pylint webscraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
